{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import torch\n",
    "from nltk.stem import PorterStemmer\n",
    "from transformers import AutoTokenizer ,AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ckpt:str='distilbert-base-uncased'\n",
    "# tokenizer=AutoTokenizer.from_pretrained(model_ckpt)\n",
    "# num_labels:int=2\n",
    "# data_labels=['positive', 'negative']\n",
    "# batch_size:int=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainer():\n",
    "    def __init__(self,\n",
    "                model_ckpt = \"distilbert-base-uncased\",\n",
    "                num_labels=2,\n",
    "                batch_size = 64,\n",
    "                num_epochs=2,\n",
    "                # data_path='D:\\Codes\\sentiment-fastapi/airline_sentiment_analysis.csv',\n",
    "                save_path=\"distilbert-base-uncased-finetuned-emotion\"\n",
    "                ):\n",
    "        \n",
    "        self.model_ckpt=model_ckpt\n",
    "        self.num_labels=num_labels\n",
    "        self.batch_size=batch_size\n",
    "        self.tokenizer=AutoTokenizer.from_pretrained(model_ckpt)\n",
    "        # self.data_path=data_path\n",
    "        self.data_labels=['positive', 'negative']\n",
    "        self.save_path=save_path\n",
    "        self.num_epochs= num_epochs\n",
    "\n",
    "\n",
    "\n",
    "    def load_data(self, path):\n",
    "        data=(pd.read_csv(path, index_col=0, header=[0])).reset_index(drop=True)\n",
    "        data.columns=['label','text']\n",
    "        data=data[['text','label']]\n",
    "        return data\n",
    "\n",
    "    def preprocess_text(self,text):\n",
    "        stemmer = PorterStemmer()\n",
    "        entity_prefixes = ['@']\n",
    "        words = []\n",
    "        for word in text.split():\n",
    "            word = word.strip()\n",
    "            if word:\n",
    "                if word[0] not in entity_prefixes:\n",
    "                    word= stemmer.stem(word)\n",
    "                    words.append(word)\n",
    "        sentence=' '.join(words)\n",
    "\n",
    "        # remove stock market tickers\n",
    "        tweet = re.sub(r'\\$\\w*', '', sentence)\n",
    "        # remove twitter abbreviations\n",
    "        tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "        # remove hyperlinks\n",
    "        tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "        # only removing the hash # sign from the word\n",
    "        tweet = re.sub(r'#', '', tweet)\n",
    "        return tweet\n",
    "\n",
    "\n",
    "    def split_data(self,data):\n",
    "        train, validate, test = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])\n",
    "        return train, validate, test\n",
    "\n",
    "    def create_dateset(self,train,validate,test):\n",
    "        train_dataset = datasets.Dataset.from_dict(train)\n",
    "        test_dataset = datasets.Dataset.from_dict(test)\n",
    "        validation_dataset=datasets.Dataset.from_dict(validate)\n",
    "        my_dataset_dict = datasets.DatasetDict({\"train\":train_dataset,\"validation\":validation_dataset,\"test\":test_dataset})\n",
    "        return my_dataset_dict\n",
    "\n",
    "    def tokenize(self,batch):\n",
    "        return self.tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "    def compute_metrics(self,pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\"accuracy\": acc, \"f1\": f1}\n",
    "    \n",
    "\n",
    "    def training(self, \n",
    "                load_path='D:\\Codes\\sentiment-fastapi/airline_sentiment_analysis.csv'\n",
    "                \n",
    "                \n",
    "                ):\n",
    "\n",
    "\n",
    "        data= self.load_data(path=load_path)\n",
    "        le = LabelEncoder()\n",
    "        data.label=le.fit(data.label).transform(data.label)\n",
    "        data.text = [self.preprocess_text(data.text[i]) for i in range(len(data))]\n",
    "        train, validate, test = self.split_data(data=data)\n",
    "        sentiment=self.create_dateset(train,validate,test)\n",
    "\n",
    "        #tokenize and encode\n",
    "        sentiment_encoded = sentiment.map(self.tokenize, batched=True, batch_size=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = (AutoModelForSequenceClassification\n",
    "                .from_pretrained(self.model_ckpt, num_labels=self.num_labels)\n",
    "                .to(device))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        logging_steps = len(sentiment_encoded[\"train\"]) // self.batch_size\n",
    "        model_name = f\"{self.model_ckpt}-finetuned-emotion\"\n",
    "        training_args = TrainingArguments(output_dir=model_name,\n",
    "                                            num_train_epochs=self.num_epochs,\n",
    "                                            learning_rate=2e-5,\n",
    "                                            per_device_train_batch_size=self.batch_size,\n",
    "                                            per_device_eval_batch_size=self.batch_size,\n",
    "                                            weight_decay=0.01,\n",
    "                                            evaluation_strategy=\"epoch\",\n",
    "                                            disable_tqdm=False,\n",
    "                                            logging_steps=logging_steps,\n",
    "                                            push_to_hub=False, \n",
    "                                            log_level=\"error\")\n",
    "\n",
    "        trainer = Trainer(model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=self.compute_metrics,\n",
    "        train_dataset=sentiment_encoded[\"train\"],\n",
    "        eval_dataset=sentiment_encoded[\"validation\"],\n",
    "        tokenizer=self.tokenizer)\n",
    "\n",
    "        # trainer\n",
    "        trainer.train();\n",
    "        trainer.save_model(self.save_path)\n",
    "        return model\n",
    "    # def train_model(data):\n",
    "\n",
    "    #     sentiment_encoded = data.map(tokenize, batched=True, batch_size=None)\n",
    "        \n",
    "    #     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #     model = (AutoModelForSequenceClassification\n",
    "    #                 .from_pretrained(model_ckpt, num_labels=2).to(device))\n",
    "    #     logging_steps = len(data[\"train\"]) // batch_size\n",
    "    #     model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "    #     training_args = TrainingArguments(output_dir=model_name,\n",
    "    #                                         num_train_epochs=2,\n",
    "    #                                         learning_rate=2e-5,\n",
    "    #                                         per_device_train_batch_size=batch_size,\n",
    "    #                                         per_device_eval_batch_size=batch_size,\n",
    "    #                                         weight_decay=0.01,\n",
    "    #                                         evaluation_strategy=\"epoch\",\n",
    "    #                                         disable_tqdm=False,\n",
    "    #                                         logging_steps=logging_steps,\n",
    "    #                                         push_to_hub=False, \n",
    "    #                                         log_level=\"error\")\n",
    "    #     trainer = Trainer(model=model, args=training_args, \n",
    "    #                         # compute_metrics=compute_metrics,\n",
    "    #                         train_dataset=data[\"train\"],\n",
    "    #                         eval_dataset=data[\"validation\"],\n",
    "    #                         tokenizer=tokenizer)\n",
    "\n",
    "    #     trainer.train()\n",
    "    #     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 109/218 [12:30<12:30,  6.88s/it]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.35ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.10ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.95ba/s]\n",
      "d:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      " 10%|█         | 109/1090 [00:48<05:59,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.31, 'learning_rate': 1.801834862385321e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 109/1090 [00:54<05:59,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1895940899848938, 'eval_accuracy': 0.9298093587521664, 'eval_f1': 0.9292327898119033, 'eval_runtime': 6.0575, 'eval_samples_per_second': 381.018, 'eval_steps_per_second': 6.108, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 216/1090 [01:44<06:45,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1575, 'learning_rate': 1.6036697247706424e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 218/1090 [01:44<05:23,  2.70it/s]\n",
      " 20%|██        | 218/1090 [01:51<05:23,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17893214523792267, 'eval_accuracy': 0.9341421143847487, 'eval_f1': 0.932725228641297, 'eval_runtime': 6.7008, 'eval_samples_per_second': 344.437, 'eval_steps_per_second': 5.522, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 324/1090 [02:40<06:06,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1055, 'learning_rate': 1.4055045871559633e-05, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 327/1090 [02:41<04:44,  2.68it/s]\n",
      " 30%|███       | 327/1090 [02:48<04:44,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17911511659622192, 'eval_accuracy': 0.938474870017331, 'eval_f1': 0.9386685488818863, 'eval_runtime': 6.2029, 'eval_samples_per_second': 372.086, 'eval_steps_per_second': 5.965, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 432/1090 [03:35<04:50,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0698, 'learning_rate': 1.2073394495412844e-05, 'epoch': 3.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 436/1090 [03:37<03:46,  2.88it/s]\n",
      " 40%|████      | 436/1090 [03:43<03:46,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19558656215667725, 'eval_accuracy': 0.9371750433275563, 'eval_f1': 0.937684060570436, 'eval_runtime': 6.1521, 'eval_samples_per_second': 375.156, 'eval_steps_per_second': 6.014, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 540/1090 [04:33<03:59,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0433, 'learning_rate': 1.0091743119266055e-05, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 545/1090 [04:35<03:08,  2.90it/s]\n",
      " 50%|█████     | 545/1090 [04:41<03:08,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2245846688747406, 'eval_accuracy': 0.9367417677642981, 'eval_f1': 0.9363813713137306, 'eval_runtime': 5.9145, 'eval_samples_per_second': 390.23, 'eval_steps_per_second': 6.256, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 648/1090 [05:27<03:14,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0281, 'learning_rate': 8.110091743119266e-06, 'epoch': 5.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 654/1090 [05:29<02:33,  2.84it/s]\n",
      " 60%|██████    | 654/1090 [05:35<02:33,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2509334683418274, 'eval_accuracy': 0.9380415944540728, 'eval_f1': 0.9380168775915559, 'eval_runtime': 6.0223, 'eval_samples_per_second': 383.245, 'eval_steps_per_second': 6.144, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 756/1090 [06:21<02:27,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0171, 'learning_rate': 6.128440366972478e-06, 'epoch': 6.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 763/1090 [06:24<01:56,  2.81it/s]\n",
      " 70%|███████   | 763/1090 [06:30<01:56,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2650224566459656, 'eval_accuracy': 0.9380415944540728, 'eval_f1': 0.9382125165868329, 'eval_runtime': 6.1942, 'eval_samples_per_second': 372.606, 'eval_steps_per_second': 5.973, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 864/1090 [07:15<01:40,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0151, 'learning_rate': 4.1467889908256885e-06, 'epoch': 7.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 872/1090 [07:18<01:16,  2.85it/s]\n",
      " 80%|████████  | 872/1090 [07:24<01:16,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27845171093940735, 'eval_accuracy': 0.938474870017331, 'eval_f1': 0.9385237339637817, 'eval_runtime': 6.1092, 'eval_samples_per_second': 377.794, 'eval_steps_per_second': 6.056, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 972/1090 [08:11<00:53,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0102, 'learning_rate': 2.1651376146788996e-06, 'epoch': 8.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 981/1090 [08:15<00:41,  2.65it/s]\n",
      " 90%|█████████ | 981/1090 [08:21<00:41,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2808539569377899, 'eval_accuracy': 0.9393414211438474, 'eval_f1': 0.9388943568875455, 'eval_runtime': 6.2388, 'eval_samples_per_second': 369.944, 'eval_steps_per_second': 5.931, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1080/1090 [09:09<00:04,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0081, 'learning_rate': 1.8348623853211012e-07, 'epoch': 9.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1090/1090 [09:13<00:00,  2.87it/s]\n",
      "100%|██████████| 1090/1090 [09:20<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2881094515323639, 'eval_accuracy': 0.9389081455805892, 'eval_f1': 0.9388348084525606, 'eval_runtime': 6.486, 'eval_samples_per_second': 355.844, 'eval_steps_per_second': 5.705, 'epoch': 10.0}\n",
      "{'train_runtime': 560.2245, 'train_samples_per_second': 123.593, 'train_steps_per_second': 1.946, 'train_loss': 0.07579997226151577, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "obj= trainer(num_epochs=10)\n",
    "model=obj.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\",\n",
    "num_labels=2,\n",
    "batch_size = 64,\n",
    "num_epochs=2,\n",
    "# data_path='D:\\Codes\\sentiment-fastapi/airline_sentiment_analysis.csv',\n",
    "save_path=\"distilbert-base-uncased-finetuned-emotion\"\n",
    "load_path='D:\\Codes\\sentiment-fastapi\\distilbert-base-uncased-finetuned-emotion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = (AutoModelForSequenceClassification\n",
    "            .from_pretrained(model_ckpt=\"distilbert-base-uncased\", num_labels=num_labels))\n",
    "    checkpoint=torch.load(load_path,\n",
    "                        map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "('distilbert-base-uncased',) is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32md:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\configuration_utils.py:601\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    600\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 601\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[0;32m    602\u001b[0m         config_file,\n\u001b[0;32m    603\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    604\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    605\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    606\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    607\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    608\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    609\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    612\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[1;32md:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\utils\\hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    283\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    285\u001b[0m         url_or_filename,\n\u001b[0;32m    286\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    287\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    288\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    289\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    290\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    292\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    293\u001b[0m     )\n\u001b[0;32m    294\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    295\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\utils\\hub.py:495\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    494\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mhead(url, headers\u001b[39m=\u001b[39mheaders, allow_redirects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, proxies\u001b[39m=\u001b[39mproxies, timeout\u001b[39m=\u001b[39metag_timeout)\n\u001b[1;32m--> 495\u001b[0m _raise_for_status(r)\n\u001b[0;32m    496\u001b[0m etag \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Linked-Etag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[0;32m    416\u001b[0m     \u001b[39m# The repo was not found and the user is not Authenticated\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m401 Client Error: Repository not found for url: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf the repo is private, make sure you are authenticated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    422\u001b[0m response\u001b[39m.\u001b[39mraise_for_status()\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error: Repository not found for url: https://huggingface.co/('distilbert-base-uncased',)/resolve/main/config.json. If the repo is private, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\Codes\\sentiment-fastapi\\trainer.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Codes/sentiment-fastapi/trainer.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# new_model=load_model()\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Codes/sentiment-fastapi/trainer.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m (AutoModelForSequenceClassification\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Codes/sentiment-fastapi/trainer.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m.\u001b[39;49mfrom_pretrained(model_ckpt, num_labels\u001b[39m=\u001b[39;49mnum_labels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Codes/sentiment-fastapi/trainer.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32md:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:423\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39m_from_auto\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m--> 423\u001b[0m     config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    424\u001b[0m         pretrained_model_name_or_path, return_unused_kwargs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, trust_remote_code\u001b[39m=\u001b[39mtrust_remote_code, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    425\u001b[0m     )\n\u001b[0;32m    426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n\u001b[0;32m    427\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32md:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:705\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[0;32m    704\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 705\u001b[0m config_dict, _ \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    707\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32md:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\configuration_utils.py:553\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    552\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 553\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    555\u001b[0m \u001b[39m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfiguration_files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n",
      "File \u001b[1;32md:\\Codes\\sentiment-fastapi\\fapi-env\\lib\\site-packages\\transformers\\configuration_utils.py:613\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[0;32m    602\u001b[0m         config_file,\n\u001b[0;32m    603\u001b[0m         cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m         user_agent\u001b[39m=\u001b[39muser_agent,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    612\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m--> 613\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    614\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier listed on \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to pass a token having \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    616\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpermission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    617\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    619\u001b[0m \u001b[39mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[0;32m    620\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    621\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m is not a valid git identifier (branch name, tag name or commit id) that exists for this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    622\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel name. Check the model page at \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    623\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mavailable revisions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    624\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: ('distilbert-base-uncased',) is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "# new_model=load_model()\n",
    "\n",
    "model = (AutoModelForSequenceClassification\n",
    "        .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "        .to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('fapi-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a924f89f863658778a2eaec4295dab149a42a16960c92d5797308b3e3b5ba295"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
